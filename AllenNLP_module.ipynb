{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "DyGntLpa6yCW"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndromedaOMA/SemEval-2026_Task4-Narrative-Similarity/blob/main/AllenNLP_module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Acesta este codul prototip pentru Course of Action"
      ],
      "metadata": {
        "id": "Gb1ylS9XSKcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -e\n",
        "\n",
        "curl -Ls https://micro.mamba.pm/api/micromamba/linux-64/latest | tar -xvj bin/micromamba\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "555ratMjvzdO",
        "outputId": "21274d1c-26f5-4741-d46e-baaf8394946e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin/micromamba\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -e\n",
        "\n",
        "./bin/micromamba create -y -n allennlp38 -c conda-forge python=3.8 pip\n",
        "./bin/micromamba run -n allennlp38 pip install -q \"torch==1.12.1\" \"allennlp==2.10.1\" \"allennlp-models==2.10.1\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJTkvW6Zv2Jl",
        "outputId": "a18e25d6-6807-4bc7-c762-d5292f48f119",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Transaction\n",
            "\n",
            "  Prefix: /root/.local/share/mamba/envs/allennlp38\n",
            "\n",
            "  Updating specs:\n",
            "\n",
            "   - python=3.8\n",
            "   - pip\n",
            "\n",
            "\n",
            "  Package              Version  Build                 Channel          Size\n",
            "─────────────────────────────────────────────────────────────────────────────\n",
            "  Install:\n",
            "─────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "  + _libgcc_mutex          0.1  conda_forge           conda-forge       3kB\n",
            "  + _openmp_mutex          4.5  2_gnu                 conda-forge      24kB\n",
            "  + bzip2                1.0.8  hda65f42_8            conda-forge     260kB\n",
            "  + ca-certificates   2026.1.4  hbd8a1cb_0            conda-forge     147kB\n",
            "  + icu                   78.2  h33c6efd_0            conda-forge      13MB\n",
            "  + ld_impl_linux-64      2.45  default_hbd61a6d_105  conda-forge     731kB\n",
            "  + libffi               3.5.2  h9ec8514_0            conda-forge      58kB\n",
            "  + libgcc              15.2.0  he0feb66_16           conda-forge       1MB\n",
            "  + libgcc-ng           15.2.0  h69a702a_16           conda-forge      27kB\n",
            "  + libgomp             15.2.0  he0feb66_16           conda-forge     603kB\n",
            "  + liblzma              5.8.1  hb9d3cd8_2            conda-forge     113kB\n",
            "  + liblzma-devel        5.8.1  hb9d3cd8_2            conda-forge     440kB\n",
            "  + libnsl               2.0.1  hb9d3cd8_1            conda-forge      34kB\n",
            "  + libsqlite           3.51.2  hf4e2dac_0            conda-forge     943kB\n",
            "  + libstdcxx           15.2.0  h934c35e_16           conda-forge       6MB\n",
            "  + libuuid             2.41.3  h5347b49_0            conda-forge      40kB\n",
            "  + libxcrypt           4.4.36  hd590300_1            conda-forge     100kB\n",
            "  + libzlib              1.3.1  hb9d3cd8_2            conda-forge      61kB\n",
            "  + ncurses                6.5  h2d0b736_3            conda-forge     892kB\n",
            "  + openssl              3.6.0  h26f9b46_0            conda-forge       3MB\n",
            "  + pip                 24.3.1  pyh8b19718_0          conda-forge       1MB\n",
            "  + python              3.8.20  h4a871b0_2_cpython    conda-forge      22MB\n",
            "  + readline               8.3  h853b02a_0            conda-forge     345kB\n",
            "  + setuptools          75.3.0  pyhd8ed1ab_0          conda-forge     780kB\n",
            "  + tk                  8.6.13  noxft_ha0e22de_103    conda-forge       3MB\n",
            "  + wheel               0.45.1  pyhd8ed1ab_0          conda-forge      63kB\n",
            "  + xz                   5.8.1  hbcc6ac9_2            conda-forge      24kB\n",
            "  + xz-gpl-tools         5.8.1  hbcc6ac9_2            conda-forge      34kB\n",
            "  + xz-tools             5.8.1  hb9d3cd8_2            conda-forge      96kB\n",
            "  + zstd                 1.5.7  hb78ec9c_6            conda-forge     601kB\n",
            "\n",
            "  Summary:\n",
            "\n",
            "  Install: 30 packages\n",
            "\n",
            "  Total download: 56MB\n",
            "\n",
            "─────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "\n",
            "\n",
            "Transaction starting\n",
            "Linking ca-certificates-2026.1.4-hbd8a1cb_0\n",
            "Linking libgomp-15.2.0-he0feb66_16\n",
            "Linking _libgcc_mutex-0.1-conda_forge\n",
            "Linking _openmp_mutex-4.5-2_gnu\n",
            "Linking libgcc-15.2.0-he0feb66_16\n",
            "Linking libstdcxx-15.2.0-h934c35e_16\n",
            "Linking liblzma-5.8.1-hb9d3cd8_2\n",
            "Linking openssl-3.6.0-h26f9b46_0\n",
            "Linking ncurses-6.5-h2d0b736_3\n",
            "Linking libzlib-1.3.1-hb9d3cd8_2\n",
            "Linking libgcc-ng-15.2.0-h69a702a_16\n",
            "Linking libuuid-2.41.3-h5347b49_0\n",
            "Linking libnsl-2.0.1-hb9d3cd8_1\n",
            "Linking libffi-3.5.2-h9ec8514_0\n",
            "Linking bzip2-1.0.8-hda65f42_8\n",
            "Linking icu-78.2-h33c6efd_0\n",
            "Linking xz-tools-5.8.1-hb9d3cd8_2\n",
            "Linking xz-gpl-tools-5.8.1-hbcc6ac9_2\n",
            "Linking liblzma-devel-5.8.1-hb9d3cd8_2\n",
            "Linking readline-8.3-h853b02a_0\n",
            "Linking zstd-1.5.7-hb78ec9c_6\n",
            "Linking tk-8.6.13-noxft_ha0e22de_103\n",
            "Linking libxcrypt-4.4.36-hd590300_1\n",
            "Linking libsqlite-3.51.2-hf4e2dac_0\n",
            "Linking xz-5.8.1-hbcc6ac9_2\n",
            "Linking ld_impl_linux-64-2.45-default_hbd61a6d_105\n",
            "Linking python-3.8.20-h4a871b0_2_cpython\n",
            "Linking pip-24.3.1-pyh8b19718_0\n",
            "Linking setuptools-75.3.0-pyhd8ed1ab_0\n",
            "Linking wheel-0.45.1-pyhd8ed1ab_0\n",
            "\n",
            "Transaction finished\n",
            "\n",
            "\n",
            "To activate this environment, use:\n",
            "\n",
            "    micromamba activate allennlp38\n",
            "\n",
            "Or to execute a single command in this environment, use:\n",
            "\n",
            "    micromamba run -n allennlp38 mycommand\n",
            "\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 776.3/776.3 MB 32.6 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 730.2/730.2 kB 23.8 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.3/5.3 MB 102.5 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 53.5 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.3/17.3 MB 108.4 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 32.4 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.1/11.1 MB 96.7 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.5/34.5 MB 42.5 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 43.5 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.5/6.5 MB 14.9 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.1/19.1 MB 15.1 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.4/4.4 MB 101.0 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 56.4 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 897.5/897.5 kB 33.4 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.2/10.2 MB 115.5 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 50.7 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 106.3 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.0/40.0 MB 52.8 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.7/13.7 MB 112.9 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 806.0/806.0 kB 31.9 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 785.1/785.1 kB 31.6 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 671.1/671.1 kB 24.8 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 108.0 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.4/12.4 MB 115.2 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.5/13.5 MB 99.3 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 78.3 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 38.5 MB/s eta 0:00:00\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 41.0 MB/s eta 0:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -e\n",
        "\n",
        "./bin/micromamba run -n allennlp38 bash -lc '\n",
        "set -e\n",
        "export LD_LIBRARY_PATH=\"$CONDA_PREFIX/lib:$LD_LIBRARY_PATH\"\n",
        "export LD_PRELOAD=\"$CONDA_PREFIX/lib/libstdc++.so.6:$CONDA_PREFIX/lib/libgcc_s.so.1\"\n",
        "export PYTHONUNBUFFERED=1\n",
        "\n",
        "python -u - <<PY\n",
        "import json, re, sys, time\n",
        "from allennlp.predictors.predictor import Predictor\n",
        "import allennlp_models.tagging\n",
        "\n",
        "def log(msg):\n",
        "    print(msg, file=sys.stderr, flush=True)\n",
        "\n",
        "SRL_URL = \"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\"\n",
        "srl = Predictor.from_path(SRL_URL, cuda_device=-1)\n",
        "\n",
        "ARG_RE = re.compile(r\"\\[([A-Z0-9]+): ([^\\]]+)\\]\")\n",
        "\n",
        "def split_sents(text):\n",
        "    text = \" \".join(str(text).split())\n",
        "    if not text:\n",
        "        return []\n",
        "    return [p.strip() for p in re.split(r\"(?<=[\\.\\!\\?\\;])\\s+\", text) if p.strip()]\n",
        "\n",
        "def parse(desc):\n",
        "    return {k: v.strip() for k, v in ARG_RE.findall(desc)}\n",
        "\n",
        "STOP_VERBS = {\n",
        "    \"be\",\"is\",\"are\",\"was\",\"were\",\"been\",\"being\",\n",
        "    \"have\",\"has\",\"had\",\"do\",\"does\",\"did\",\n",
        "    \"will\",\"would\",\"can\",\"could\",\"should\",\"may\",\"might\",\"must\"\n",
        "}\n",
        "\n",
        "def srl_events(text, keep=(\"ARG0\",\"ARG1\",\"ARG2\"), min_args=1):\n",
        "    events = []\n",
        "    for sent in split_sents(text):\n",
        "        out = srl.predict(sentence=sent)\n",
        "        for fr in out.get(\"verbs\", []):\n",
        "            d = parse(fr.get(\"description\",\"\"))\n",
        "            verb = (fr.get(\"verb\") or d.get(\"V\",\"\")).strip().lower()\n",
        "            if not verb or verb in STOP_VERBS:\n",
        "                continue\n",
        "\n",
        "            args = [d[a].lower() for a in keep if a in d]\n",
        "            if len(args) < min_args:\n",
        "                continue\n",
        "\n",
        "            events.append(\" | \".join([verb] + args))\n",
        "    return events\n",
        "\n",
        "input_path  = \"test_track_a.jsonl\"\n",
        "output_path = \"events_test.jsonl\"\n",
        "\n",
        "with open(input_path, \"r\", encoding=\"utf-8\") as fin, \\\n",
        "     open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
        "\n",
        "    for line in fin:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        ex = json.loads(line)\n",
        "        out = {\n",
        "            \"anchor_events\": srl_events(ex.get(\"anchor_text\",\"\")),\n",
        "            \"A_events\": srl_events(ex.get(\"text_a\",\"\")),\n",
        "            \"B_events\": srl_events(ex.get(\"text_b\",\"\")),\n",
        "            label\": bool(ex.get(\"text_a_is_closer\", False))\n",
        "        }\n",
        "\n",
        "        fout.write(json.dumps(out, ensure_ascii=False) + \"\\n\")\n",
        "PY\n",
        "'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPhDZhNQv-GI",
        "outputId": "d64c0af1-3f05-4422-f158-2942d95add84",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://storage.googleapis.com/allennlp-public-mo… ━━━ 100% 0:… 406…\n",
            "                                                                            MB  \n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Collecting en-core-web-sm==3.3.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.8/12.8 MB 42.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from en-core-web-sm==3.3.0) (3.3.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.11)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.11.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.24.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (75.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (25.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.7.4.1 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.5.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.4.1)\n",
            "Requirement already satisfied: language-data>=1.2 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.4.0)\n",
            "Requirement already satisfied: pathlib-abc==0.1.1 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2026.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.1.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.2.1)\n",
            "Installing collected packages: en-core-web-sm\n",
            "Successfully installed en-core-web-sm-3.3.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages/google/api_core/_python_version_support.py:246: FutureWarning: You are using a non-supported Python version (3.8.20). Google will not post any further updates to google.api_core supporting this Python version. Please upgrade to the latest Python version, or at least Python 3.10, and then update google.api_core.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages/google/auth/__init__.py:52: FutureWarning: \n",
            "    You are using a Python version 3.8 past its end of life. Google will update\n",
            "    google-auth with critical bug fixes on a best-effort basis, but not\n",
            "    with any other fixes or features. Please upgrade your Python version,\n",
            "    and then update google-auth.\n",
            "    \n",
            "  warnings.warn(eol_message.format(\"3.8\"), FutureWarning)\n",
            "/root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages/google/oauth2/__init__.py:38: FutureWarning: \n",
            "    You are using a Python version 3.8 past its end of life. Google will update\n",
            "    google-auth with critical bug fixes on a best-effort basis, but not\n",
            "    with any other fixes or features. Please upgrade your Python version,\n",
            "    and then update google-auth.\n",
            "    \n",
            "  warnings.warn(eol_message.format(\"3.8\"), FutureWarning)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "\rDownloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]\rDownloading: 100%|██████████| 48.0/48.0 [00:00<00:00, 195kB/s]\n",
            "\rDownloading:   0%|          | 0.00/570 [00:00<?, ?B/s]\rDownloading: 100%|██████████| 570/570 [00:00<00:00, 2.83MB/s]\n",
            "\rDownloading:   0%|          | 0.00/226k [00:00<?, ?B/s]\rDownloading: 100%|██████████| 226k/226k [00:00<00:00, 10.4MB/s]\n",
            "\rDownloading:   0%|          | 0.00/455k [00:00<?, ?B/s]\rDownloading:  44%|████▍     | 201k/455k [00:00<00:00, 1.68MB/s]\rDownloading: 100%|██████████| 455k/455k [00:00<00:00, 3.54MB/s]\n",
            "\rDownloading:   0%|          | 0.00/420M [00:00<?, ?B/s]\rDownloading:   0%|          | 1.00k/420M [00:01<160:00:09, 765B/s]\rDownloading:   1%|▏         | 5.78M/420M [00:01<01:14, 5.84MB/s]  \rDownloading:   3%|▎         | 11.8M/420M [00:01<00:33, 12.8MB/s]\rDownloading:   4%|▍         | 18.2M/420M [00:01<00:20, 20.8MB/s]\rDownloading:   6%|▌         | 24.2M/420M [00:01<00:14, 28.2MB/s]\rDownloading:   7%|▋         | 29.8M/420M [00:01<00:12, 33.9MB/s]\rDownloading:   8%|▊         | 35.4M/420M [00:01<00:10, 39.5MB/s]\rDownloading:  10%|▉         | 41.1M/420M [00:02<00:08, 44.2MB/s]\rDownloading:  11%|█▏        | 47.5M/420M [00:02<00:07, 50.0MB/s]\rDownloading:  13%|█▎        | 53.7M/420M [00:02<00:07, 54.0MB/s]\rDownloading:  14%|█▍        | 59.7M/420M [00:02<00:06, 56.4MB/s]\rDownloading:  16%|█▌        | 65.6M/420M [00:02<00:08, 44.9MB/s]\rDownloading:  17%|█▋        | 71.6M/420M [00:02<00:07, 49.1MB/s]\rDownloading:  18%|█▊        | 77.6M/420M [00:02<00:06, 52.7MB/s]\rDownloading:  20%|█▉        | 83.5M/420M [00:02<00:06, 55.0MB/s]\rDownloading:  21%|██▏       | 89.5M/420M [00:02<00:06, 57.1MB/s]\rDownloading:  23%|██▎       | 95.2M/420M [00:03<00:06, 55.8MB/s]\rDownloading:  24%|██▍       | 101M/420M [00:03<00:05, 58.3MB/s] \rDownloading:  26%|██▌       | 107M/420M [00:03<00:05, 59.8MB/s]\rDownloading:  27%|██▋       | 113M/420M [00:03<00:05, 54.0MB/s]\rDownloading:  28%|██▊       | 119M/420M [00:03<00:06, 50.1MB/s]\rDownloading:  29%|██▉       | 124M/420M [00:03<00:06, 47.4MB/s]\rDownloading:  31%|███       | 128M/420M [00:03<00:06, 47.3MB/s]\rDownloading:  32%|███▏      | 133M/420M [00:03<00:06, 49.3MB/s]\rDownloading:  33%|███▎      | 139M/420M [00:03<00:05, 52.4MB/s]\rDownloading:  34%|███▍      | 144M/420M [00:04<00:05, 51.2MB/s]\rDownloading:  36%|███▌      | 150M/420M [00:04<00:05, 54.1MB/s]\rDownloading:  37%|███▋      | 156M/420M [00:04<00:04, 55.5MB/s]\rDownloading:  39%|███▊      | 162M/420M [00:04<00:04, 57.7MB/s]\rDownloading:  40%|███▉      | 168M/420M [00:04<00:04, 58.6MB/s]\rDownloading:  41%|████▏     | 173M/420M [00:04<00:04, 59.4MB/s]\rDownloading:  43%|████▎     | 179M/420M [00:04<00:04, 60.4MB/s]\rDownloading:  44%|████▍     | 185M/420M [00:04<00:04, 61.2MB/s]\rDownloading:  46%|████▌     | 191M/420M [00:04<00:03, 61.4MB/s]\rDownloading:  47%|████▋     | 197M/420M [00:05<00:08, 29.0MB/s]\rDownloading:  49%|████▊     | 204M/420M [00:05<00:06, 35.7MB/s]\rDownloading:  50%|█████     | 210M/420M [00:05<00:05, 42.3MB/s]\rDownloading:  52%|█████▏    | 217M/420M [00:05<00:04, 48.3MB/s]\rDownloading:  53%|█████▎    | 224M/420M [00:05<00:03, 53.7MB/s]\rDownloading:  55%|█████▍    | 231M/420M [00:05<00:03, 58.0MB/s]\rDownloading:  57%|█████▋    | 238M/420M [00:05<00:03, 61.9MB/s]\rDownloading:  58%|█████▊    | 244M/420M [00:06<00:02, 63.1MB/s]\rDownloading:  60%|█████▉    | 251M/420M [00:06<00:02, 61.1MB/s]\rDownloading:  61%|██████    | 257M/420M [00:06<00:06, 27.7MB/s]\rDownloading:  62%|██████▏   | 261M/420M [00:06<00:05, 29.5MB/s]\rDownloading:  63%|██████▎   | 266M/420M [00:06<00:05, 31.6MB/s]\rDownloading:  64%|██████▍   | 270M/420M [00:07<00:04, 33.5MB/s]\rDownloading:  65%|██████▌   | 274M/420M [00:07<00:04, 34.4MB/s]\rDownloading:  66%|██████▌   | 278M/420M [00:07<00:04, 35.2MB/s]\rDownloading:  67%|██████▋   | 282M/420M [00:07<00:03, 36.4MB/s]\rDownloading:  68%|██████▊   | 286M/420M [00:07<00:03, 37.7MB/s]\rDownloading:  69%|██████▉   | 290M/420M [00:07<00:03, 38.7MB/s]\rDownloading:  70%|██████▉   | 294M/420M [00:07<00:03, 39.0MB/s]\rDownloading:  71%|███████   | 298M/420M [00:07<00:03, 40.5MB/s]\rDownloading:  72%|███████▏  | 302M/420M [00:07<00:03, 40.7MB/s]\rDownloading:  73%|███████▎  | 306M/420M [00:07<00:02, 41.4MB/s]\rDownloading:  74%|███████▎  | 310M/420M [00:08<00:02, 40.7MB/s]\rDownloading:  75%|███████▍  | 314M/420M [00:08<00:02, 39.3MB/s]\rDownloading:  76%|███████▌  | 317M/420M [00:08<00:02, 38.8MB/s]\rDownloading:  76%|███████▋  | 321M/420M [00:08<00:02, 37.7MB/s]\rDownloading:  78%|███████▊  | 326M/420M [00:08<00:02, 41.1MB/s]\rDownloading:  79%|███████▉  | 331M/420M [00:08<00:02, 44.0MB/s]\rDownloading:  80%|███████▉  | 335M/420M [00:08<00:01, 44.6MB/s]\rDownloading:  81%|████████  | 340M/420M [00:08<00:01, 45.5MB/s]\rDownloading:  82%|████████▏ | 344M/420M [00:08<00:01, 44.9MB/s]\rDownloading:  83%|████████▎ | 348M/420M [00:09<00:01, 44.2MB/s]\rDownloading:  84%|████████▍ | 353M/420M [00:09<00:01, 44.6MB/s]\rDownloading:  85%|████████▌ | 357M/420M [00:09<00:01, 45.2MB/s]\rDownloading:  86%|████████▌ | 362M/420M [00:09<00:01, 45.5MB/s]\rDownloading:  87%|████████▋ | 366M/420M [00:09<00:01, 44.9MB/s]\rDownloading:  88%|████████▊ | 370M/420M [00:09<00:01, 43.3MB/s]\rDownloading:  89%|████████▉ | 375M/420M [00:09<00:01, 44.8MB/s]\rDownloading:  90%|█████████ | 379M/420M [00:09<00:00, 44.5MB/s]\rDownloading:  91%|█████████▏| 383M/420M [00:09<00:00, 43.1MB/s]\rDownloading:  92%|█████████▏| 388M/420M [00:09<00:00, 43.2MB/s]\rDownloading:  93%|█████████▎| 392M/420M [00:10<00:00, 43.9MB/s]\rDownloading:  94%|█████████▍| 396M/420M [00:10<00:00, 43.8MB/s]\rDownloading:  95%|█████████▌| 400M/420M [00:10<00:00, 42.4MB/s]\rDownloading:  96%|█████████▋| 404M/420M [00:10<00:00, 42.0MB/s]\rDownloading:  97%|█████████▋| 409M/420M [00:10<00:00, 43.9MB/s]\rDownloading:  98%|█████████▊| 413M/420M [00:10<00:00, 42.5MB/s]\rDownloading:  99%|█████████▉| 417M/420M [00:10<00:00, 42.4MB/s]\rDownloading: 100%|██████████| 420M/420M [00:10<00:00, 41.0MB/s]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Spacy models 'en_core_web_sm' not found.  Downloading and installing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test pentru NLP"
      ],
      "metadata": {
        "id": "93jBEluJ05mB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -e\n",
        "\n",
        "./bin/micromamba run -n allennlp38 bash -lc '\n",
        "set -e\n",
        "export LD_LIBRARY_PATH=\"$CONDA_PREFIX/lib:$LD_LIBRARY_PATH\"\n",
        "export LD_PRELOAD=\"$CONDA_PREFIX/lib/libstdc++.so.6:$CONDA_PREFIX/lib/libgcc_s.so.1\"\n",
        "export PYTHONUNBUFFERED=1\n",
        "export TOKENIZERS_PARALLELISM=false\n",
        "\n",
        "python -u - <<PY\n",
        "import re, sys, pathlib\n",
        "from allennlp.predictors.predictor import Predictor\n",
        "import allennlp_models.tagging\n",
        "\n",
        "ANCHOR_PATH = \"anchor.txt\"\n",
        "A_PATH = \"a.txt\"\n",
        "B_PATH = \"b.txt\"\n",
        "\n",
        "SRL_URL = \"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\"\n",
        "srl = Predictor.from_path(SRL_URL, cuda_device=-1)\n",
        "\n",
        "ARG_RE = re.compile(r\"\\\\[([A-Z0-9\\\\-]+): ([^\\\\]]+)\\\\]\")\n",
        "\n",
        "def normalize_text(text: str) -> str:\n",
        "    text = str(text).replace(\"\\\\u00a0\", \" \")\n",
        "    text = \" \".join(text.split())\n",
        "    return text\n",
        "\n",
        "def split_sents(text: str):\n",
        "    text = normalize_text(text)\n",
        "    if not text:\n",
        "        return []\n",
        "\n",
        "    return [p.strip() for p in re.split(r\"(?<=[\\\\.\\\\!\\\\?\\\\;])\\\\s+\", text) if p.strip()]\n",
        "\n",
        "def parse(desc: str):\n",
        "    return {k: v.strip() for k, v in ARG_RE.findall(desc)}\n",
        "\n",
        "STOP_VERBS = {\n",
        "    \"be\",\"is\",\"are\",\"was\",\"were\",\"been\",\"being\",\n",
        "    \"have\",\"has\",\"had\",\"do\",\"does\",\"did\",\n",
        "    \"will\",\"would\",\"can\",\"could\",\"should\",\"may\",\"might\",\"must\"\n",
        "}\n",
        "\n",
        "def srl_events(text, keep=(\"ARG0\",\"ARG1\",\"ARG2\"), min_args=1):\n",
        "    events = []\n",
        "    for sent in split_sents(text):\n",
        "        out = srl.predict(sentence=sent)\n",
        "        for fr in out.get(\"verbs\", []):\n",
        "            d = parse(fr.get(\"description\",\"\"))\n",
        "            verb = (fr.get(\"verb\") or d.get(\"V\",\"\")).strip().lower()\n",
        "            if not verb or verb in STOP_VERBS:\n",
        "                continue\n",
        "\n",
        "            args = [d[a].lower() for a in keep if a in d]\n",
        "            if len(args) < min_args:\n",
        "                continue\n",
        "\n",
        "            events.append(\" | \".join([verb] + args))\n",
        "    return events\n",
        "\n",
        "def load_text(path: str) -> str:\n",
        "    p = pathlib.Path(path)\n",
        "    if not p.exists():\n",
        "        sys.exit(f\"[ERROR] File not found: {path}\")\n",
        "    return p.read_text(encoding=\"utf-8\").strip()\n",
        "\n",
        "def inspect_text(title: str, text: str):\n",
        "    print(\"\\\\n\" + \"=\"*100)\n",
        "    print(title)\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    text = normalize_text(text)\n",
        "    if not text:\n",
        "        print(\"(empty)\")\n",
        "        return\n",
        "\n",
        "    sents = split_sents(text)\n",
        "    print(f\"[SENTENCES] {len(sents)}\")\n",
        "    for i, sent in enumerate(sents, 1):\n",
        "        print(f\"{i:02d}. {sent}\")\n",
        "\n",
        "    print(\"\\\\n[SRL RAW]\")\n",
        "    for i, sent in enumerate(sents, 1):\n",
        "        out = srl.predict(sentence=sent)\n",
        "        verbs = out.get(\"verbs\", [])\n",
        "        print(f\"\\\\nSentence {i:02d}: {sent}\")\n",
        "        if not verbs:\n",
        "            print(\"  (no verb frames)\")\n",
        "            continue\n",
        "        for j, fr in enumerate(verbs, 1):\n",
        "            v = fr.get(\"verb\",\"\")\n",
        "            desc = fr.get(\"description\",\"\")\n",
        "            print(f\"  Frame {j:02d} | verb={v}\")\n",
        "            print(f\"    {desc}\")\n",
        "\n",
        "    print(\"\\\\n[EVENTS extracted] (ARG0, ARG1, ARG2)\")\n",
        "    ev = srl_events(text)\n",
        "    if not ev:\n",
        "        print(\"  (no events)\")\n",
        "    else:\n",
        "        for i, e in enumerate(ev, 1):\n",
        "            print(f\"  {i:02d}. {e}\")\n",
        "\n",
        "anchor = load_text(ANCHOR_PATH)\n",
        "a_text = load_text(A_PATH)\n",
        "b_text = load_text(B_PATH)\n",
        "\n",
        "inspect_text(\"ANCHOR\", anchor)\n",
        "inspect_text(\"A\", a_text)\n",
        "inspect_text(\"B\", b_text)\n",
        "PY\n",
        "'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Z1KONpgXcZMY",
        "outputId": "3cdbaef6-90a8-4d96-edff-1abc69d60be0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "ANCHOR\n",
            "====================================================================================================\n",
            "[SENTENCES] 3\n",
            "01. Having been a victim of bullying, life at his new school does not take a turn to the better for Leo Weiß (played by Torge Oelrich (de).\n",
            "02. In order to no longer be the misfit and to exercise power over his fellow students, he secretly infects them with a zombie virus.\n",
            "03. As he is the only one who knows that a training in dancing, handicrafts or mathematics can transform them back to normal, Leo soon becomes the school's highly acclaimed hero.\n",
            "\n",
            "[SRL RAW]\n",
            "\n",
            "Sentence 01: Having been a victim of bullying, life at his new school does not take a turn to the better for Leo Weiß (played by Torge Oelrich (de).\n",
            "  Frame 01 | verb=Having\n",
            "    [V: Having] been a victim of bullying , life at his new school does not take a turn to the better for Leo Weiß ( played by Torge Oelrich ( de ) .\n",
            "  Frame 02 | verb=been\n",
            "    Having [V: been] [ARG2: a victim of bullying] , life at his new school does not take a turn to the better for Leo Weiß ( played by Torge Oelrich ( de ) .\n",
            "  Frame 03 | verb=does\n",
            "    Having been a victim of bullying , life at his new school [V: does] not take a turn to the better for Leo Weiß ( played by Torge Oelrich ( de ) .\n",
            "  Frame 04 | verb=take\n",
            "    [R-ARG0: Having been a victim of bullying] , [ARG0: life at his new school] does [ARGM-NEG: not] [V: take] [ARG1: a turn] [ARGM-DIR: to the better] [ARGM-GOL: for Leo Weiß ( played by Torge Oelrich (] [ARGM-DIR: de )] .\n",
            "  Frame 05 | verb=played\n",
            "    Having been a victim of bullying , life at his new school does not take a turn to the better for [ARG1: Leo Weiß] ( [V: played] [ARG0: by Torge Oelrich ( de] ) .\n",
            "\n",
            "Sentence 02: In order to no longer be the misfit and to exercise power over his fellow students, he secretly infects them with a zombie virus.\n",
            "  Frame 01 | verb=be\n",
            "    In order to [ARGM-TMP: no longer] [V: be] [ARG2: the misfit] and to exercise power over his fellow students , he secretly infects them with a zombie virus .\n",
            "  Frame 02 | verb=exercise\n",
            "    In order to no longer be the misfit and to [V: exercise] [ARG1: power over his fellow students] , he secretly infects them with a zombie virus .\n",
            "  Frame 03 | verb=infects\n",
            "    [ARGM-PRP: In order to no longer be the misfit and to exercise power over his fellow students] , [ARG0: he] [ARGM-MNR: secretly] [V: infects] [ARG1: them] [ARG2: with a zombie virus] .\n",
            "\n",
            "Sentence 03: As he is the only one who knows that a training in dancing, handicrafts or mathematics can transform them back to normal, Leo soon becomes the school's highly acclaimed hero.\n",
            "  Frame 01 | verb=is\n",
            "    As [ARG1: he] [V: is] [ARG2: the only one who knows that a training in dancing , handicrafts or mathematics can transform them back to normal] , Leo soon becomes the school 's highly acclaimed hero .\n",
            "  Frame 02 | verb=knows\n",
            "    As he is [ARG0: the only one] [R-ARG0: who] [V: knows] [ARG1: that a training in dancing , handicrafts or mathematics can transform them back to normal] , Leo soon becomes the school 's highly acclaimed hero .\n",
            "  Frame 03 | verb=can\n",
            "    As he is the only one who knows that a training in dancing , handicrafts or mathematics [V: can] transform them back to normal , Leo soon becomes the school 's highly acclaimed hero .\n",
            "  Frame 04 | verb=transform\n",
            "    As he is the only one who knows that [ARG0: a training in dancing , handicrafts or mathematics] [ARGM-MOD: can] [V: transform] [ARG1: them] [ARG3: back] [ARG2: to normal] , Leo soon becomes the school 's highly acclaimed hero .\n",
            "  Frame 05 | verb=becomes\n",
            "    [ARGM-CAU: As he is the only one who knows that a training in dancing , handicrafts or mathematics can transform them back to normal] , [ARG1: Leo] [ARGM-TMP: soon] [V: becomes] [ARG2: the school 's highly acclaimed hero] .\n",
            "  Frame 06 | verb=acclaimed\n",
            "    As he is the only one who knows that a training in dancing , handicrafts or mathematics can transform them back to normal , Leo soon becomes the school 's [ARGM-EXT: highly] [V: acclaimed] [ARG1: hero] .\n",
            "\n",
            "[EVENTS extracted] (ARG0, ARG1, ARG2)\n",
            "  01. take | life at his new school | a turn\n",
            "  02. played | by torge oelrich ( de | leo weiß\n",
            "  03. exercise | power over his fellow students\n",
            "  04. infects | he | them | with a zombie virus\n",
            "  05. knows | the only one | that a training in dancing , handicrafts or mathematics can transform them back to normal\n",
            "  06. transform | a training in dancing , handicrafts or mathematics | them | to normal\n",
            "  07. becomes | leo | the school 's highly acclaimed hero\n",
            "  08. acclaimed | hero\n",
            "\n",
            "====================================================================================================\n",
            "A\n",
            "====================================================================================================\n",
            "[SENTENCES] 3\n",
            "01. Alberto is an employee who is the Italian average of society of the Fifties.\n",
            "02. Alberto is a go-getter, attached only to his work, and believes that everyone meets him wants to bring Alberto bad luck.\n",
            "03. Alberto refuses every contact with other people, but soon finds himself caught in misunderstandings and so the people, to take revenge on him and his meanness, force him to change his identity.\n",
            "\n",
            "[SRL RAW]\n",
            "\n",
            "Sentence 01: Alberto is an employee who is the Italian average of society of the Fifties.\n",
            "  Frame 01 | verb=is\n",
            "    [ARG1: Alberto] [V: is] [ARG2: an employee who is the Italian average of society of the Fifties] .\n",
            "  Frame 02 | verb=is\n",
            "    Alberto is [ARG1: an employee] [R-ARG1: who] [V: is] [ARG2: the Italian average of society of the Fifties] .\n",
            "\n",
            "Sentence 02: Alberto is a go-getter, attached only to his work, and believes that everyone meets him wants to bring Alberto bad luck.\n",
            "  Frame 01 | verb=is\n",
            "    [ARG1: Alberto] [V: is] [ARG2: a go - getter ,] [ARGM-PRD: attached only to his work] , and believes that everyone meets him wants to bring Alberto bad luck .\n",
            "  Frame 02 | verb=attached\n",
            "    [ARG1: Alberto] is a go - getter , [V: attached] [ARGM-ADV: only] [ARG2: to his work] , and believes that everyone meets him wants to bring Alberto bad luck .\n",
            "  Frame 03 | verb=believes\n",
            "    [ARG0: Alberto] is a go - getter , attached only to his work , and [V: believes] [ARG1: that everyone meets him wants to bring Alberto bad luck] .\n",
            "  Frame 04 | verb=meets\n",
            "    Alberto is a go - getter , attached only to his work , and believes that [ARG0: everyone] [V: meets] [ARG1: him] wants to bring Alberto bad luck .\n",
            "  Frame 05 | verb=wants\n",
            "    Alberto is a go - getter , attached only to his work , and believes that [ARG0: everyone meets him] [V: wants] [ARG1: to bring Alberto bad luck] .\n",
            "  Frame 06 | verb=bring\n",
            "    Alberto is a go - getter , attached only to his work , and believes that [ARG0: everyone meets him] wants to [V: bring] [ARG2: Alberto] [ARG1: bad luck] .\n",
            "\n",
            "Sentence 03: Alberto refuses every contact with other people, but soon finds himself caught in misunderstandings and so the people, to take revenge on him and his meanness, force him to change his identity.\n",
            "  Frame 01 | verb=refuses\n",
            "    [ARG0: Alberto] [V: refuses] [ARG1: every contact with other people] , but soon finds himself caught in misunderstandings and so the people , to take revenge on him and his meanness , force him to change his identity .\n",
            "  Frame 02 | verb=finds\n",
            "    [ARG0: Alberto] refuses every contact with other people , but [ARGM-TMP: soon] [V: finds] [ARG1: himself caught in misunderstandings] and so the people , to take revenge on him and his meanness , force him to change his identity .\n",
            "  Frame 03 | verb=caught\n",
            "    Alberto refuses every contact with other people , but soon finds [ARG1: himself] [V: caught] [ARG2: in misunderstandings] and so the people , to take revenge on him and his meanness , force him to change his identity .\n",
            "  Frame 04 | verb=take\n",
            "    Alberto refuses every contact with other people , but soon finds himself caught in misunderstandings and so [ARG0: the people] , to [V: take] [ARG1: revenge on him and his meanness] , force him to change his identity .\n",
            "  Frame 05 | verb=force\n",
            "    Alberto refuses every contact with other people , but soon finds himself caught in misunderstandings and so [ARG0: the people] , [ARGM-PRP: to take revenge on him and his meanness] , [V: force] [ARG1: him] [ARG2: to change his identity] .\n",
            "  Frame 06 | verb=change\n",
            "    Alberto refuses every contact with other people , but soon finds himself caught in misunderstandings and so the people , to take revenge on him and his meanness , force [ARG0: him] to [V: change] [ARG1: his identity] .\n",
            "\n",
            "[EVENTS extracted] (ARG0, ARG1, ARG2)\n",
            "  01. attached | alberto | to his work\n",
            "  02. believes | alberto | that everyone meets him wants to bring alberto bad luck\n",
            "  03. meets | everyone | him\n",
            "  04. wants | everyone meets him | to bring alberto bad luck\n",
            "  05. bring | everyone meets him | bad luck | alberto\n",
            "  06. refuses | alberto | every contact with other people\n",
            "  07. finds | alberto | himself caught in misunderstandings\n",
            "  08. caught | himself | in misunderstandings\n",
            "  09. take | the people | revenge on him and his meanness\n",
            "  10. force | the people | him | to change his identity\n",
            "  11. change | him | his identity\n",
            "\n",
            "====================================================================================================\n",
            "B\n",
            "====================================================================================================\n",
            "[SENTENCES] 4\n",
            "01. A lab mix-up accidentally swaps a vaccine with a virus that turns a high school full of students and teachers into flesh-eating zombies.\n",
            "02. But all is not lost: New student Aki discovers that the swim team is immune to the plague.\n",
            "03. With the school rampaged by ravenous monsters, the girls engage in an over-the-top orgy of gory violence to save the day.\n",
            "04. Sasa Handa, Yuria Hidaka and Hiromitsu Kiba star in this comic creature feature.\n",
            "\n",
            "[SRL RAW]\n",
            "\n",
            "Sentence 01: A lab mix-up accidentally swaps a vaccine with a virus that turns a high school full of students and teachers into flesh-eating zombies.\n",
            "  Frame 01 | verb=swaps\n",
            "    [ARG0: A lab mix - up] [ARGM-MNR: accidentally] [V: swaps] [ARG1: a vaccine] [ARG2: with a virus that turns a high school full of students and teachers into flesh - eating zombies] .\n",
            "  Frame 02 | verb=turns\n",
            "    A lab mix - up accidentally swaps a vaccine with [ARG0: a virus] [R-ARG0: that] [V: turns] [ARG1: a high school full of students and teachers] [ARG2: into flesh - eating zombies] .\n",
            "  Frame 03 | verb=eating\n",
            "    A lab mix - up accidentally swaps a vaccine with a virus that turns a high school full of students and teachers into [ARG1: flesh] - [V: eating] [ARG0: zombies] .\n",
            "\n",
            "Sentence 02: But all is not lost: New student Aki discovers that the swim team is immune to the plague.\n",
            "  Frame 01 | verb=is\n",
            "    But all [V: is] not lost : New student Aki discovers that the swim team is immune to the plague .\n",
            "  Frame 02 | verb=lost\n",
            "    [ARGM-DIS: But] [ARG1: all] is [ARGM-NEG: not] [V: lost] : New student Aki discovers that the swim team is immune to the plague .\n",
            "  Frame 03 | verb=discovers\n",
            "    But all is not lost : [ARG0: New student Aki] [V: discovers] [ARG1: that the swim team is immune to the plague] .\n",
            "  Frame 04 | verb=is\n",
            "    But all is not lost : New student Aki discovers that [ARG1: the swim team] [V: is] [ARG2: immune to the plague] .\n",
            "\n",
            "Sentence 03: With the school rampaged by ravenous monsters, the girls engage in an over-the-top orgy of gory violence to save the day.\n",
            "  Frame 01 | verb=rampaged\n",
            "    With [ARG1: the school] [V: rampaged] [ARG0: by ravenous monsters] , the girls engage in an over - the - top orgy of gory violence to save the day .\n",
            "  Frame 02 | verb=engage\n",
            "    [ARGM-ADV: With the school rampaged by ravenous monsters] , [ARG0: the girls] [V: engage] [ARG2: in an over - the - top orgy of gory violence] [ARGM-PRP: to save the day] .\n",
            "  Frame 03 | verb=save\n",
            "    With the school rampaged by ravenous monsters , the girls engage in an over - the - top orgy of gory violence to [V: save] [ARG1: the day] .\n",
            "\n",
            "Sentence 04: Sasa Handa, Yuria Hidaka and Hiromitsu Kiba star in this comic creature feature.\n",
            "  (no verb frames)\n",
            "\n",
            "[EVENTS extracted] (ARG0, ARG1, ARG2)\n",
            "  01. swaps | a lab mix - up | a vaccine | with a virus that turns a high school full of students and teachers into flesh - eating zombies\n",
            "  02. turns | a virus | a high school full of students and teachers | into flesh - eating zombies\n",
            "  03. eating | zombies | flesh\n",
            "  04. lost | all\n",
            "  05. discovers | new student aki | that the swim team is immune to the plague\n",
            "  06. rampaged | by ravenous monsters | the school\n",
            "  07. engage | the girls | in an over - the - top orgy of gory violence\n",
            "  08. save | the day\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages/google/api_core/_python_version_support.py:246: FutureWarning: You are using a non-supported Python version (3.8.20). Google will not post any further updates to google.api_core supporting this Python version. Please upgrade to the latest Python version, or at least Python 3.10, and then update google.api_core.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages/google/auth/__init__.py:52: FutureWarning: \n",
            "    You are using a Python version 3.8 past its end of life. Google will update\n",
            "    google-auth with critical bug fixes on a best-effort basis, but not\n",
            "    with any other fixes or features. Please upgrade your Python version,\n",
            "    and then update google-auth.\n",
            "    \n",
            "  warnings.warn(eol_message.format(\"3.8\"), FutureWarning)\n",
            "/root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages/google/oauth2/__init__.py:38: FutureWarning: \n",
            "    You are using a Python version 3.8 past its end of life. Google will update\n",
            "    google-auth with critical bug fixes on a best-effort basis, but not\n",
            "    with any other fixes or features. Please upgrade your Python version,\n",
            "    and then update google-auth.\n",
            "    \n",
            "  warnings.warn(eol_message.format(\"3.8\"), FutureWarning)\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Demo"
      ],
      "metadata": {
        "id": "DyGntLpa6yCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -e\n",
        "\n",
        "./bin/micromamba run -n allennlp38 python - <<'PY'\n",
        "from allennlp.predictors.predictor import Predictor\n",
        "import allennlp_models.tagging\n",
        "\n",
        "SRL_URL = \"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\"\n",
        "predictor = Predictor.from_path(SRL_URL, cuda_device=-1)\n",
        "\n",
        "sentence = \"Dan found the purse and returned it to Anna.\"\n",
        "out = predictor.predict(sentence=sentence)\n",
        "\n",
        "print(\"Words:\", out[\"words\"])\n",
        "print(\"\\nFrames:\")\n",
        "for v in out[\"verbs\"]:\n",
        "    print(v[\"verb\"], \"=>\", v[\"description\"])\n",
        "PY\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBJcV594v2uS",
        "outputId": "7b46aed8-aacb-4938-a3e7-b59ce577718c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Collecting en-core-web-sm==3.3.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.8/12.8 MB 84.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from en-core-web-sm==3.3.0) (3.3.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.17)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.11)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.10)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.11.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.24.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
            "Requirement already satisfied: jinja2 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (75.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (25.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.7.4.1 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.5.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.4.1)\n",
            "Requirement already satisfied: language-data>=1.2 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.4.0)\n",
            "Requirement already satisfied: pathlib-abc==0.1.1 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2026.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.1.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.2.1)\n",
            "Installing collected packages: en-core-web-sm\n",
            "Successfully installed en-core-web-sm-3.3.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Words: ['Dan', 'found', 'the', 'purse', 'and', 'returned', 'it', 'to', 'Anna', '.']\n",
            "\n",
            "Frames:\n",
            "found => [ARG0: Dan] [V: found] [ARG1: the purse] and returned it to Anna .\n",
            "returned => [ARG0: Dan] found the purse and [V: returned] [ARG1: it] [ARG2: to Anna] .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages/google/api_core/_python_version_support.py:246: FutureWarning: You are using a non-supported Python version (3.8.20). Google will not post any further updates to google.api_core supporting this Python version. Please upgrade to the latest Python version, or at least Python 3.10, and then update google.api_core.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages/google/auth/__init__.py:52: FutureWarning: \n",
            "    You are using a Python version 3.8 past its end of life. Google will update\n",
            "    google-auth with critical bug fixes on a best-effort basis, but not\n",
            "    with any other fixes or features. Please upgrade your Python version,\n",
            "    and then update google-auth.\n",
            "    \n",
            "  warnings.warn(eol_message.format(\"3.8\"), FutureWarning)\n",
            "/root/.local/share/mamba/envs/allennlp38/lib/python3.8/site-packages/google/oauth2/__init__.py:38: FutureWarning: \n",
            "    You are using a Python version 3.8 past its end of life. Google will update\n",
            "    google-auth with critical bug fixes on a best-effort basis, but not\n",
            "    with any other fixes or features. Please upgrade your Python version,\n",
            "    and then update google-auth.\n",
            "    \n",
            "  warnings.warn(eol_message.format(\"3.8\"), FutureWarning)\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Spacy models 'en_core_web_sm' not found.  Downloading and installing.\n"
          ]
        }
      ]
    }
  ]
}